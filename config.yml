controller_name: 'mppi-tf'  # name of the controller to be used - does not matter for Cartpole Gym
predictor_name: predictor_ODE_tf    # One of ["predictor_ODE", "predictor_ODE_tf", "predictor_autoregressive_tf"]
cost_function_name: cost_function_default

predictor:
  predictor_intermediate_steps: 5       # Number of Euler steps. Increase for more accuracy.
  dt: 0.02                              # sec
  disable_individual_compilation: false
  # NET_NAME can be a path to a model. If it's only a model name, the path from config_testing.yml will be used
  NET_NAME: GRU-6IN-32H1-32H2-5OUT-0  # Applies only if predictor name is predictor_autoregressive_tf

cost_function:
  cost_function_default:
    R: 0.2

controller:
  cem-tf:
    seed: null                          # If null, random seed based on datetime is used
    mpc_horizon: 40                       # steps
    cem_outer_it: 3                    #how many outer iterations to use
    cem_initial_action_stdev: 0.5
    num_rollouts: 200          #how many rollouts per outer cem iteration
    cem_stdev_min: 0.01
    cem_R: 1
    cem_best_k: 40
    warmup: false
    warmup_iterations: 250
    controller_logging: True
  cem-gmm-tf:
    seed: null                          # If null, random seed based on datetime is used
    mpc_horizon: 40                       # steps
    cem_outer_it: 3                    #how many outer iterations to use
    num_rollouts: 200          #how many rollouts per outer cem iteration
    cem_stdev_min: 0.01
    cem_initial_action_stdev: 0.5
    cem_R: 1
    cem_best_k: 40
    controller_logging: True
  cem-naive-grad-tf:
    seed: null                          # If null, random seed based on datetime is used
    mpc_horizon: 35                       # steps
    cem_outer_it: 1                       # how many outer iterations to use
    num_rollouts: 200                     # how many rollouts per outer cem iteration
    cem_stdev_min: 0.1
    cem_initial_action_stdev: 0.5
    cem_R: 1
    cem_best_k: 40
    learning_rate: 0.1
    gradmax_clip: 10
    controller_logging: True
  cem-grad-bharadhwaj-tf:
    seed: null                          # If null, random seed based on datetime is used
    controller_logging: true
    mpc_horizon: 50                       # steps
    learning_rate: 0.05
    adam_beta_1: 0.9
    adam_beta_2: 0.999
    adam_epsilon: 1.0e-08
    cem_R: 1
    num_rollouts: 32
    cem_best_k: 8
    cem_outer_it: 2
    cem_initial_action_stdev: 2
    cem_stdev_min: 1.e-6
    gradmax_clip: 5
    warmup: false
    warmup_iterations: 250
  gradient-tf:
    seed: null                            # If null, random seed based on datetime is used
    mpc_horizon: 35                       # steps
    learning_rate: 0.05
    adam_beta_1: 0.9
    adam_beta_2: 0.999
    adam_epsilon: 1.0e-07
    rtol: 1.0e-3
    gradient_steps: 5
    num_rollouts: 40
    initial_action_stdev: 0.5
    gradmax_clip: 5
    warmup: false
    warmup_iterations: 250
    controller_logging: True
  mppi-optimize-tf:
    seed: null                            # If null, random seed based on datetime is used
    mppi_LR: 0.02
    adam_beta_1: 0.4                      #default: 0.9
    adam_beta_2: 0.8                      #default: 0.999
    adam_epsilon: 1.0e-7                  #default: 1.0e-7
    gradmax_clip: 1000
    mpc_horizon: 35                       # steps
    num_rollouts: 400                     # Number of Monte Carlo samples
    cc_weight: 1.0
    R: 1.0                                # How much to punish Q
    LBD: 100.0                            # Cost parameter lambda
    NU: 1000.0                            # Exploration variance
    SQRTRHOINV: 0.02
    GAMMA: 1.00                           # Future cost discount
    SAMPLING_TYPE: "interpolated"         # One of ["iid", "random_walk", "uniform", "repeated", "interpolated"]
    optim_steps: 10
    controller_logging: True
  dist-adam-resamp2-tf:
    seed: null                            # If null, random seed based on datetime is used
    mpc_horizon: 40                       # steps
    SAMPLING_TYPE: interpolated
    interpolation_step: 10
    learning_rate: 0.05
    adam_beta_1: 0.9
    adam_beta_2: 0.999
    adam_epsilon: 1.0e-08
    gradmax_clip: 5
    rtol: 1.0e-3
    num_rollouts: 32
    opt_keep_k: 8
    outer_its: 2
    resamp_per: 10
    sample_stdev: 0.5
    warmup: false
    warmup_iterations: 250
    controller_logging: True
  rpgd-tf:
    seed: null                            # If null, random seed based on datetime is used
    mpc_horizon: 40                       # steps
    SAMPLING_TYPE: interpolated
    interpolation_step: 10
    learning_rate: 0.05
    adam_beta_1: 0.9
    adam_beta_2: 0.999
    adam_epsilon: 1.0e-08
    gradmax_clip: 5
    rtol: 1.0e-3
    num_rollouts: 32
    opt_keep_k: 8
    outer_its: 2
    resamp_per: 10
    sample_stdev: 0.5
    warmup: false
    warmup_iterations: 250
    controller_logging: True
  controller-rpgd-me-tf:
    seed: null                            # If null, random seed based on datetime is used
    mpc_horizon: 40                       # steps
    SAMPLING_TYPE: null
    SAMPLING_DISTRIBUTION: uniform  # "normal" or "uniform"
    interpolation_step: 10
    learning_rate: 0.01
    adam_beta_1: 0.9
    adam_beta_2: 0.999
    adam_epsilon: 1.0e-08
    maximum_entropy_alpha: 0.0
    gradmax_clip: 10
    rtol: 1.0e-3
    num_rollouts: 32
    opt_keep_k: 0
    outer_its: 25
    resamp_per: 1
    sample_stdev: 0.5
    warmup: false
    warmup_iterations: 250
  controller-rpgd_ml_tf:
    seed: null                            # If null, random seed based on datetime is used
    mpc_horizon: 40                       # steps
    SAMPLING_DISTRIBUTION: uniform  # "normal" or "uniform"
    SAMPLING_TYPE: null
    interpolation_step: 10
    learning_rate: 0.01
    adam_beta_1: 0.9
    adam_beta_2: 0.999
    adam_epsilon: 1.0e-08
    maximum_entropy_alpha: 0.1
    gradmax_clip: 10
    rtol: 1.0e-3
    num_rollouts: 32
    opt_keep_k: 8
    outer_its: 5
    resamp_per: 1
    sample_stdev: 0.5
    warmup: false
    warmup_iterations: 250
  controller-rpgd_particle:
    seed: null                            # If null, random seed based on datetime is used
    mpc_horizon: 40                       # steps
    SAMPLING_DISTRIBUTION: uniform  # "normal" or "uniform"
    SAMPLING_TYPE: null
    interpolation_step: 10
    learning_rate: 0.01
    adam_beta_1: 0.9
    adam_beta_2: 0.999
    adam_epsilon: 1.0e-08
    maximum_entropy_alpha: 0.1
    gradmax_clip: 10
    rtol: 1.0e-3
    num_rollouts: 32
    opt_keep_k: 8
    outer_its: 5
    resamp_per: 1
    sample_stdev: 0.5
    warmup: false
    warmup_iterations: 250
  mppi-var-tf:
    seed: null                          # If null, random seed based on datetime is used
    mpc_horizon: 35                       # steps
    num_rollouts: 400                     # Number of Monte Carlo samples
    SAMPLING_TYPE: "interpolated" #if interpolated: linear interpolation; else iid
    interpolation_step: 10                #interpolation stepsize when sampling
    cc_weight: 1.0
    R: 1.0                                # How much to punish Q
    # mc stands for mathematical correct, as this controller uses the formula from the paper
    LBD_mc: 10.0                          # Cost parameter lambda
    SQRTRHOINV_mc: 0.002                  # Sampling variance
    NU_mc: 20.0                           # Exploration variance
    GAMMA: 1.00                           # Future cost discount
    LR: 1000                              # Learning rate for adaption of variance, !!! Set to 0 to retrieve a mppi version in accordance with mppi paper
    STDEV_min: 0.01                       # Maximal variance for sampling
    STDEV_max: 10                         # Minimal sampling variance for sampling
    max_grad_norm: 100000                 # max norm of gradient such that ||gradient||_2
    controller_logging: True
  mppi:
    seed: null                            # Seed for rng, for MPPI only, put null to set random seed (do it when you generate data for training!)
    dt: 0.02                              # sec
    mpc_horizon: 35                       # steps
    num_rollouts: 3500                    # Number of Monte Carlo samples
    update_every: 1                       # Cost weighted update of inputs every ... steps
    GP_NAME: 'SGP_30'                     # Applies only if predictor name is GP
    dd_weight: 120.0
    ep_weight: 50000.0
    ekp_weight: 0.01
    ekc_weight: 5.0
    cc_weight: 1.0
    ccrc_weight: 1.0
    cost_noise: 0.0                       # Noise on stage cost weights by +/- this value, we usually set 0.5 to explore various controllers while collecting data for training, 0 othewise
    control_noise: 0.0                    # Noise on top of the calculated control input by +/- this value, we usually set 0.5 to explore various controllers while collecting data for training, 0.1 to test an not-ideal case
    R: 1.0                                # How much to punish Q
    LBD: 100.0                            # Cost parameter lambda
    NU: 1000.0                            # Exploration variance
    SQRTRHOINV: 0.02                      # Sampling variance
    GAMMA: 1.00                           # Future cost discount
    SAMPLING_TYPE: "interpolated"         # One of ["iid", "random_walk", "uniform", "repeated", "interpolated"]
    controller_logging: False                        # Collect and show detailed insights into the controller's behavior
    WASH_OUT_LEN: 100                     # Only matters if RNN used as predictor; For how long MPPI should be desactivated (replaced either with LQR or random input) to give memory units time to settle
  mppi-tf:
    seed: null                          # Seed for rng, for MPPI only, put null to set random seed (do it when you generate data for training!)
    mpc_horizon: 35                       # steps
    num_rollouts: 3500                    # Number of Monte Carlo samples
    update_every: 1                       # Cost weighted update of inputs every ... steps
    GP_NAME: 'SGP_30'                     # Applies only if predictor name is GP
    cc_weight: 1.0
    cost_noise: 0.0                       # Noise on stage cost weights by +/- this value, we usually set 0.5 to explore various controllers while collecting data for training, 0 othewise
    control_noise: 0.0                    # Noise on top of the calculated control input by +/- this value, we usually set 0.5 to explore various controllers while collecting data for training, 0.1 to test an not-ideal case
    R: 1.0                                # How much to punish Q
    LBD: 100.0                            # Cost parameter lambda
    NU: 1000.0                            # Exploration variance
    SQRTRHOINV: 0.03                      # Sampling variance
    GAMMA: 1.00                           # Future cost discount
    SAMPLING_TYPE: "interpolated"         # One of ["iid", "random_walk", "uniform", "repeated", "interpolated"]
    controller_logging: False                        # Collect and show detailed insights into the controller's behavior
    WASH_OUT_LEN: 100                     # Only matters if RNN used as predictor; For how long MPPI should be desactivated (replaced either with LQR or random input) to give memory units time to settle
    CLIP_CONTROL_INPUT: [1.0]             # How to clip control input, symmetric
  random-action:
    seed: null                          # Seed for rng, for MPPI only, put null to set random seed (do it when you generate data for training!)
    mpc_horizon: 35                       # steps
    num_rollouts: 3500                    # Number of Monte Carlo samples
    num_rollouts: 320
    controller_logging: False                        # Collect and show detailed insights into the controller's behavior
  custom-mpc-scipy:
    seed: null                          # If null, random seed based on datetime is used
    # method: 'L-BFGS-B'
    method: 'SLSQP'
    ftol: 1.0e-8
    mpc_horizon: 10                       # steps
    # weights
    wr: 0.001  # rterm
    l1: 100.0  # angle_cost
    l1_2: 0.0  # angle_sin_cost
    l2: 0.0  # angleD_cost
    l3: 0.0  # position_cost
    l4: 0.01  # positionD_cost
    m1: 0.0  # angle_sin_cost
    m2: 0.0  # angleD_cost
    m3: 0.0  # position_cost
    m4: 0.0  # positionD_cost
    controller_logging: True
  do-mpc-discrete:
    dt: 0.02  # s
    mpc_horizon: 50                       # steps
    num_rollouts: 1
    controller_logging: True
  do-mpc:
    seed: null                          # If null, random seed based on datetime is used
    mpc_horizon: 50                       # steps
    num_rollouts: 1
    # Perturbation factors:
    # Change of output from optimal
    p_Q: 0.00
    # Random change of cost function by factor
    p_position: 0.0
    p_positionD: 0.0
    p_angle: 0.0
    # Cost factor
    l_angle: 0.1
    l_position: 1.0
    l_positionD: 0.1
    controller_logging: True
  lqr:
    seed: null  # Seed for rng, for lqr only, put null to set random seed (do it when you generate data for training!)
    Q: [10.0, 1.0, 1.0, 1.0]
    R: 10.0
    control_noise: 1.0
    controller_logging: True
  pid:
    P_angle: 9.0
    I_angle: 0.0
    D_angle: 0.0
    P_position: 0.1
    I_position: 0.0
    D_position: 0.1
    controller_logging: True
  mpc-opti:
    mpc_horizon: 10                       # steps
    controller_logging: True
  neural-imitator-tf:
    seed: null                            # If null, random seed based on datetime is used
    PATH_TO_MODELS: './Control_Toolkit_ASF/Controllers/models_for_neural_imitator_tf/'
    mpc_horizon: 40
    num_rollouts: 1
    controller_logging: True
  neural-imitator-pytorch:
    seed: null                            # If null, random seed based on datetime is used
    PATH_TO_MODELS: './Control_Toolkit_ASF/Controllers/models_for_neural_imitator_tf/'
    mpc_horizon: 40
    num_rollouts: 1
    controller_logging: True
  secloc:
    log_base: 1.05
    dt: 1 # In the Arduino code is 1000
    ref_period: 1
    dead_band: 0.0025  # Radians
    pid_Kp: 15.0
    pid_Kd: 0.0
    pid_Ki: 1.0
    #secloc_motor_map: 128
cartpole:
  cost_function: 'quadratic-boundary-grad' # from 'quadratic-boundary', 'quadratic-boundary-grad', 'quadratic-boundary-nonconvex', 'default'
  actuator_noise: 0.0  # TODO: There already exists a noise entry
  mode: stabilization
  seed: 1873  # This is a seed for rng for CartPole instance class only. If null random seed based on datetime is used
  PATH_TO_EXPERIMENT_RECORDINGS_DEFAULT: './Experiment_Recordings/'   # Where to save experiment recording per default
  m: 0.087  # mass of pole, kg # Checked by Antonio & Tobi
  M: 0.230  # mass of cart, kg # Checked by Antonio
  L: "0.395/2.0"  # HALF (!!!) length of pend, m # Checked by Antonio & Tobi
  u_max: 2.62  # max force produced by the motor, N # Checked by Marcin
  M_fric: 4.77  # cart friction on track, N/m/s # Checked by Marcin
  J_fric: 2.5e-4  # friction coefficient on angular velocity in pole joint, Nm/rad/s # Checked by Marcin
  v_max: 0.8  # max DC motor speed, m/s, in absense of friction, used for motor back EMF model # TODO: not implemented in model, but needed for MPC
  cart_length: 4.4e-2  # m, checked by Marcin&Asude
  usable_track_length: 44.0e-2  # m, checked by Marcin&Asude
  controlDisturbance: 0.0  # disturbance, as factor of u_max # I used 0.2-0.5 for data collection
  controlBias: 0.0  # bias of control input
  g: 9.81  # absolute value of gravity acceleration, m/s^2
  k: "1.0/3.0"  # Dimensionless factor of moment of inertia of the pole with length 2L: I: (1/3)*m*(2L)^2 = (4/3)*m*(L)^2
  latency: 0.0 # s
  noise:
    noise_mode: 'OFF'
    sigma_angle: 0.0  # As measured by Asude
    sigma_position: 0.0005
    sigma_angleD: 0.075 # This is much smaller than would result from sigma_angle under assumption of iir filter+derviative calculation; the theoretical value would be 2.28
    sigma_positionD: 0.005
  num_control_inputs: 1
  dd_weight: 600.0
  ep_weight: 20000.0
  ekp_weight: 80.0
  ekc_weight: 20.0
  cc_weight: 1.0
  ccrc_weight: 1.0


data_generator:
  seed: 1  # If null random seed based on datetime is used
