controller:
  general:
    cost_function: 'quadratic-boundary-grad' # from 'quadratic-boundary', 'quadratic-boundary-grad', 'quadratic-boundary-nonconvex', 'default'
  cem:
    SEED: "None"
    dt: 0.02                              # sec
    mpc_horizon: 1.0                      # sec
    cem_outer_it: 5                    #how many outer iterations to use
    cem_rollouts: 80          #how many rollouts per outer cem iteration
    cem_predictor_type: "EulerTF"               # One of ["Euler", "NeuralNet"]
    CEM_NET_NAME: 'GRU-6IN-32H1-32H2-5OUT-0' # Applies only if predictor_type is NeuralNet
    cem_stdev_min: 0.1
    cem_R: 1
    cem_ccrc_weight: 1
    cem_best_k: 4
    cem_LR: 0.1
  cem-naive-grad:
    SEED: "None"
    dt: 0.02                              # sec
    mpc_horizon: 1.0                      # sec
    cem_outer_it: 5                    #how many outer iterations to use
    cem_rollouts: 80          #how many rollouts per outer cem iteration
    cem_predictor_type: "EulerTF"               # One of ["Euler", "NeuralNet"]
    CEM_NET_NAME: 'GRU-6IN-32H1-32H2-5OUT-0' # Applies only if predictor_type is NeuralNet
    cem_stdev_min: 0.05
    cem_R: 1
    cem_ccrc_weight: 1
    cem_best_k: 4
    cem_LR: 0.001
    gradmax_clip: 10
  mppi-optimize:
    SEED: "None"
    LR: 0.02
    adam_beta_1: 0.4    #default: 0.9
    adam_beta_2: 0.8  #default: 0.999
    adam_epsilon: 1e-07 #default: 1e-07
    gradmax_clip: 1000
    dt: 0.02                              # sec
    mpc_horizon: 1.0                      # sec
    num_rollouts: 400                     # Number of Monte Carlo samples
    predictor_type: "EulerTF"               # One of ["Euler", "NeuralNet"]
    NET_NAME: 'GRU-6IN-32H1-32H2-5OUT-0'  # Applies only if predictor_type is NeuralNet
    cc_weight: 1.0
    R: 1.0                                # How much to punish Q
    LBD: 100.0                            # Cost parameter lambda
    NU: 1000.0                            # Exploration variance
    SQRTRHOINV: 0.02
    GAMMA: 1.00                           # Future cost discount
    SAMPLING_TYPE: "interpolated"         # One of ["iid", "random_walk", "uniform", "repeated", "interpolated"]
    optim_steps: 10
  dist-adam-resamp2:
    SEED: "None"
    dt: 0.02
    mpc_horizon: 1.0
    predictor_type: "EulerTF"               # One of ["Euler", "NeuralNet", "EulerTF"]
    NET_NAME: 'GRU-6IN-32H1-32H2-5OUT-0'  #DOES NOT WORK YET!!! Applies only if predictor_type is NeuralNet
    resamp_per: 1                         # determines after how many steps the control plans are resamples
    sample_stdev: 0.5                     #sampling variance of control action
    LR: 0.002                             #learning rate parameter fro adam
    adam_beta_1: 0.4    #default: 0.9      adam hyperparameter
    adam_beta_2: 0.8 #default: 0.999       adam hyperparameter
    adam_epsilon: 1e-07 #default: 1e-07    adam hyperparameter. consult https://ruder.io/optimizing-gradient-descent/ for information
    opt_keep_k: 5                          #how many plans should be kept for warmstarting when resampling, has to be smaller or equal num_rollouts, set equal num_rollouts for degenerate case without any resampling
    num_rollouts: 20                      # number of parallel optimizations
    SAMPLING_TYPE: "interpolated" #if interpolated: linear interpolation; else iid
    warmup: True                          #whether or not we warmstart the controller. If true, first iteration will do mpc_horizon/dt*outer_its optimizations
    interpolation_step: 10                #interpolation stepsize when sampling
    outer_its: 20                         #number of optimization iterations
    gradmax_clip: 250                     #maximal gradient entry to be kept, is ||gradient||_inf <= gradmax_clip
  mppi-var:
    SEED: "None"
    dt: 0.02                              # sec
    mpc_horizon: 1.0                      # sec
    num_rollouts: 400                     # Number of Monte Carlo samples
    SAMPLING_TYPE: "interpolated" #if interpolated: linear interpolation; else iid
    interpolation_step: 10                #interpolation stepsize when sampling
    cc_weight: 1.0
    predictor_type: "EulerTF"               # One of ["Euler", "NeuralNet", "EulerTF"]  # EulerTF needs SQRTRHOINV=0.03
    NET_NAME: 'GRU-6IN-32H1-32H2-5OUT-0'  #DOES NOT WORK YET!!! Applies only if predictor_type is NeuralNet
    R: 1.0                                # How much to punish Q
    # mc stands for mathematical correct, as this controller uses the formula from the paper
    LBD_mc: 10.0                          # Cost parameter lambda
    SQRTRHOINV_mc: 0.002                  # Sampling variance
    NU_mc: 20.0                           # Exploration variance
    GAMMA: 1.00                           # Future cost discount
    LR: 1000                             # Learning rate for adaption of variance, !!! Set to 0 to retrieve a mppi version in accordance with mppi paper
    STDEV_min: 0.01                        # Maximal variance for sampling
    STDEV_max: 10                       # Minimal sampling variance for sampling
    max_grad_norm: 100000                    # max norm of gradient such that ||gradient||_2
  mppi:
    SEED: "None"                            # Seed for rng, for MPPI only, put "None" to set random seed (do it when you generate data for training!)
    dt: 0.02                              # sec
    mpc_horizon: 0.7                      # sec
    num_rollouts: 10000                      # Number of Monte Carlo samples
    update_every: 1                       # Cost weighted update of inputs every ... steps
    predictor_type: "EulerTF"               # One of ["EulerTF", "NeuralNet", "GP"]
    NET_NAME: 'GRU-6IN-32H1-32H2-5OUT-1'  # Applies only if predictor_type is NeuralNet
    GP_NAME: 'SGP_10'  # Applies only if predictor_type is GP
    dd_weight: 2000.0
    ep_weight: 3000.0
    ekp_weight: 15.0
    ekc_weight: 0.0
    cc_weight: 0.0
    ccrc_weight: 0.0
    cost_noise: 0.0                       # Noise on stage cost weights by +/- this value, we usually set 0.5 to explore various controllers while collecting data for training, 0 othewise
    control_noise: 0.0                    # Noise on top of the calculated control input by +/- this value, we usually set 0.5 to explore various controllers while collecting data for training, 0.1 to test an not-ideal case
    R: 1.0                                # How much to punish Q
    LBD: 100.0                            # Cost parameter lambda
    NU: 1000.0                            # Exploration variance
    SQRTRHOINV: 0.03                      # Sampling variance
    GAMMA: 1.00                           # Future cost discount
    SAMPLING_TYPE: "interpolated"         # One of ["iid", "random_walk", "uniform", "repeated", "interpolated"]
    LOGGING: False                        # Collect and show detailed insights into the controller's behavior
    WASH_OUT_LEN: 100                     # Only matters if RNN used as predictor; For how long MPPI should be desactivated (replaced either with LQR or random input) to give memory units time to settle
    CLIP_CONTROL_INPUT: [0.8]            # How to clip control input, symmetric
  custom_mpc_scipy:
    DT: 0.1
    # method: 'L-BFGS-B'
    method: 'SLSQP'
    ftol: 1.0e-8
    mpc_horizon: 10
    # weights
    wr: 0.001  # rterm
    l1: 100.0  # angle_cost
    l1_2: 0.0  # angle_sin_cost
    l2: 0.0  # angleD_cost
    l3: 0.0  # position_cost
    l4: 0.01  # positionD_cost
    m1: 0.0  # angle_sin_cost
    m2: 0.0  # angleD_cost
    m3: 0.0  # position_cost
    m4: 0.0  # positionD_cost
  do_mpc_discrete:
    dt_mpc_simulation: 0.02  # s
    mpc_horizon: 50
  do_mpc:
    dt_mpc_simulation: 0.02  # s
    mpc_horizon: 50
    # Perturbation factors:
    # Change of output from optimal
    p_Q: 0.00
    # Random change of cost function by factor
    p_position: 0.0
    p_positionD: 0.0
    p_angle: 0.0
    # Cost factor
    l_angle: 0.1
    l_position: 1.0
    l_positionD: 0.1
  lqr:
    Q: [10.0, 1.0, 1.0, 1.0]
    R: 10.0
    SEED: 'None'                            # Seed for rng, for lqr only, put "None" to set random seed (do it when you generate data for training!)
    control_noise: 1.0
  pid:
    P_angle: 9.0
    I_angle: 0.0
    D_angle: 0.0
    P_position: 0.1
    I_position: 0.0
    D_position: 0.1
  mpc_opti:
    dt_mpc_simulation: 0.2  # s
    mpc_horizon: 10
  neural_imitator_tf:
    net_name: 'GRU-6IN-32H1-32H2-1OUT-0'
    PATH_TO_MODELS: './Controllers/models_for_neural_imitator_tf/'
cartpole:
  SEED: None  # This is a seed for rng for CartPole instance class only. If "None" random seed based on datetime is used
  PATH_TO_CONTROLLERS: './Controllers/'  # Path where controllers are stored
  PATH_TO_EXPERIMENT_RECORDINGS_DEFAULT: './Experiment_Recordings/'   # Where to save experiment recording per default
  m: 0.087  # mass of pole, kg # Checked by Antonio & Tobi
  M: 0.230  # mass of cart, kg # Checked by Antonio
  L: "0.395/2.0"  # HALF (!!!) length of pend, m # Checked by Antonio & Tobi
  u_max: 2.62  # max force produced by the motor, N # Checked by Marcin
  M_fric: 4.77  # cart friction on track, N/m/s # Checked by Marcin
  J_fric: 2.5e-4  # friction coefficient on angular velocity in pole joint, Nm/rad/s # Checked by Marcin
  v_max: 0.8  # max DC motor speed, m/s, in absense of friction, used for motor back EMF model # TODO: not implemented in model, but needed for MPC
  cart_length: 4.4e-2  # m, checked by Marcin&Asude
  usable_track_length: 44.0e-2  # m, checked by Marcin&Asude
  controlDisturbance: 0.0  # disturbance, as factor of u_max # Had 0.2 for data collection
  controlBias: 0.0  # bias of control input
  g: 9.81  # absolute value of gravity acceleration, m/s^2
  k: "1.0/3.0"  # Dimensionless factor of moment of inertia of the pole with length 2L: I: (1/3)*m*(2L)^2 = (4/3)*m*(L)^2
  latency: 0.0 # s
  noise:
    noise_mode: 'OFF'
    sigma_angle: 0.0  # As measured by Asude
    sigma_position: 0.0005
    sigma_angleD: 0.075 # This is much smaller than would result from sigma_angle under assumption of iir filter+derviative calculation; the theoretical value would be 2.28
    sigma_positionD: 0.005
  num_control_inputs: 1


data_generator:
  SEED: 1  # If "None" random seed based on datetime is used