#!/bin/bash
#SBATCH --array=1-25             # Create an array job with task IDs from 1 to 1152
#SBATCH --cpus-per-task=1        # Assign the required number of CPUs per task
#SBATCH --time=8:00:00           # Set the maximum job time
#SBATCH --mem-per-cpu=4G
#SBATCH --output=./others/EulerClusterScripts/EulerTerminalOutput/Vertical_Angle_Offset_30_11_2024/Training/slurm-%A_%a.out   # Output file

# Create output and error directories if they do not exist
mkdir -p ./others/EulerClusterScripts/EulerTerminalOutput/Vertical_Angle_Offset_30_11_2024/Training/

source $HOME/miniconda3/bin/activate
conda activate CPS39

# Use SLURM_ARRAY_TASK_ID for the model index directly since it ranges from 1 to 50
i=$SLURM_ARRAY_TASK_ID
export PYTHONPATH="/cluster/home/paluchm/CartPoleSimulation:$PYTHONPATH"

# Run the Python script with the specific index
python ./SI_Toolkit_ASF/Run/A2_Train_Network.py -i $i

