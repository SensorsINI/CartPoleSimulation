
Number of samples in training set: 133560
The mean number of samples from each experiment used for training is 4452.0 with variance 0.0
Number of samples in validation set: 22260

86/86 [==============================] - 2s 10ms/step - loss: 0.4298

Validation loss before starting training is 0.42980900406837463
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 layers_0 (Dense)            (None, 50, 32)            256       
                                                                 
 activation (Activation)     (None, 50, 32)            0         
                                                                 
 layers_1 (Dense)            (None, 50, 32)            1056      
                                                                 
 activation_1 (Activation)   (None, 50, 32)            0         
                                                                 
 layers_2 (Dense)            (None, 50, 1)             33        
                                                                 
=================================================================
Total params: 1345 (5.25 KB)
Trainable params: 1345 (5.25 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
Epoch 1/60
521/521 [==============================] - 15s 24ms/step - loss: 0.1400 - val_loss: 0.0709 - lr: 0.0100

Epoch 2/60
521/521 [==============================] - 13s 24ms/step - loss: 0.0629 - val_loss: 0.0562 - lr: 0.0100

Epoch 3/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0512 - val_loss: 0.0481 - lr: 0.0100

Epoch 4/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0446 - val_loss: 0.0420 - lr: 0.0100

Epoch 5/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0406 - val_loss: 0.0393 - lr: 0.0100

Epoch 6/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0379 - val_loss: 0.0383 - lr: 0.0100

Epoch 7/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0362 - val_loss: 0.0375 - lr: 0.0100

Epoch 8/60
521/521 [==============================] - 13s 25ms/step - loss: 0.0348 - val_loss: 0.0358 - lr: 0.0100

Epoch 9/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0338 - val_loss: 0.0341 - lr: 0.0100

Epoch 10/60
521/521 [==============================] - 13s 24ms/step - loss: 0.0326 - val_loss: 0.0350 - lr: 0.0100

Epoch 11/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0319 - val_loss: 0.0325 - lr: 0.0100

Epoch 12/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0312 - val_loss: 0.0318 - lr: 0.0100

Epoch 13/60
521/521 [==============================] - 13s 24ms/step - loss: 0.0306 - val_loss: 0.0317 - lr: 0.0100

Epoch 14/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0299 - val_loss: 0.0314 - lr: 0.0100

Epoch 15/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0295 - val_loss: 0.0319 - lr: 0.0100

Epoch 16/60
521/521 [==============================] - 13s 25ms/step - loss: 0.0289 - val_loss: 0.0305 - lr: 0.0100

Epoch 17/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0286 - val_loss: 0.0309 - lr: 0.0100

Epoch 18/60
521/521 [==============================] - ETA: 0s - loss: 0.0284

Epoch 18: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.
521/521 [==============================] - 12s 23ms/step - loss: 0.0284 - val_loss: 0.0308 - lr: 0.0100

Epoch 19/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0271 - val_loss: 0.0301 - lr: 0.0050

Epoch 20/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0270 - val_loss: 0.0301 - lr: 0.0050

Epoch 21/60
521/521 [==============================] - 13s 25ms/step - loss: 0.0270 - val_loss: 0.0301 - lr: 0.0050

Epoch 22/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0268 - val_loss: 0.0302 - lr: 0.0050

Epoch 23/60
521/521 [==============================] - ETA: 0s - loss: 0.0267

Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.
521/521 [==============================] - 12s 23ms/step - loss: 0.0267 - val_loss: 0.0306 - lr: 0.0050

Epoch 24/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0261 - val_loss: 0.0294 - lr: 0.0025

Epoch 25/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0260 - val_loss: 0.0292 - lr: 0.0025

Epoch 26/60
521/521 [==============================] - 13s 26ms/step - loss: 0.0260 - val_loss: 0.0295 - lr: 0.0025

Epoch 27/60
521/521 [==============================] - ETA: 0s - loss: 0.0259

Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.
521/521 [==============================] - 12s 23ms/step - loss: 0.0259 - val_loss: 0.0293 - lr: 0.0025

Epoch 28/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0256 - val_loss: 0.0291 - lr: 0.0012

Epoch 29/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0255 - val_loss: 0.0292 - lr: 0.0012

Epoch 30/60
521/521 [==============================] - ETA: 0s - loss: 0.0255

Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.
521/521 [==============================] - 12s 23ms/step - loss: 0.0255 - val_loss: 0.0294 - lr: 0.0012

Epoch 31/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0253 - val_loss: 0.0293 - lr: 6.2500e-04

Epoch 32/60
521/521 [==============================] - 14s 26ms/step - loss: 0.0253 - val_loss: 0.0290 - lr: 6.2500e-04

Epoch 33/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0253 - val_loss: 0.0291 - lr: 6.2500e-04

Epoch 34/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0253 - val_loss: 0.0290 - lr: 6.2500e-04

Epoch 35/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0252 - val_loss: 0.0290 - lr: 6.2500e-04

Epoch 36/60
519/521 [============================>.] - ETA: 0s - loss: 0.0252

Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.
521/521 [==============================] - 12s 23ms/step - loss: 0.0252 - val_loss: 0.0290 - lr: 6.2500e-04

Epoch 37/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0251 - val_loss: 0.0290 - lr: 3.1250e-04

Epoch 38/60
520/521 [============================>.] - ETA: 0s - loss: 0.0251

Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.
521/521 [==============================] - 13s 24ms/step - loss: 0.0251 - val_loss: 0.0290 - lr: 3.1250e-04

Epoch 39/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0251 - val_loss: 0.0290 - lr: 1.5625e-04

Epoch 40/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0251 - val_loss: 0.0289 - lr: 1.5625e-04

Epoch 41/60
521/521 [==============================] - 14s 27ms/step - loss: 0.0250 - val_loss: 0.0290 - lr: 1.5625e-04

Epoch 42/60
521/521 [==============================] - ETA: 0s - loss: 0.0250

Epoch 42: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.
521/521 [==============================] - 12s 24ms/step - loss: 0.0250 - val_loss: 0.0290 - lr: 1.5625e-04

Epoch 43/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 7.8125e-05

Epoch 44/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 7.8125e-05

Epoch 45/60
521/521 [==============================] - ETA: 0s - loss: 0.0250

Epoch 45: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.
521/521 [==============================] - 12s 24ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 7.8125e-05

Epoch 46/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 3.9062e-05

Epoch 47/60
521/521 [==============================] - ETA: 0s - loss: 0.0250

Epoch 47: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.
521/521 [==============================] - 12s 24ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 3.9062e-05

Epoch 48/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 1.9531e-05

Epoch 49/60
521/521 [==============================] - ETA: 0s - loss: 0.0250

Epoch 49: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.
521/521 [==============================] - 12s 24ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 1.9531e-05

Epoch 50/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 9.7656e-06

Epoch 51/60
518/521 [============================>.] - ETA: 0s - loss: 0.0250

Epoch 51: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.
521/521 [==============================] - 15s 28ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 9.7656e-06

Epoch 52/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 4.8828e-06

Epoch 53/60
521/521 [==============================] - ETA: 0s - loss: 0.0250

Epoch 53: ReduceLROnPlateau reducing learning rate to 2.441406195430318e-06.
521/521 [==============================] - 12s 24ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 4.8828e-06

Epoch 54/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 2.4414e-06

Epoch 55/60
520/521 [============================>.] - ETA: 0s - loss: 0.0250

Epoch 55: ReduceLROnPlateau reducing learning rate to 1.220703097715159e-06.
521/521 [==============================] - 12s 24ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 2.4414e-06

Epoch 56/60
521/521 [==============================] - 13s 24ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 1.2207e-06

Epoch 57/60
521/521 [==============================] - ETA: 0s - loss: 0.0250

Epoch 57: ReduceLROnPlateau reducing learning rate to 6.103515488575795e-07.
521/521 [==============================] - 12s 24ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 1.2207e-06

Epoch 58/60
521/521 [==============================] - 12s 24ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 6.1035e-07

Epoch 59/60
517/521 [============================>.] - ETA: 0s - loss: 0.0250

Epoch 59: ReduceLROnPlateau reducing learning rate to 3.0517577442878974e-07.
521/521 [==============================] - 12s 24ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 6.1035e-07

Epoch 60/60
521/521 [==============================] - 12s 23ms/step - loss: 0.0250 - val_loss: 0.0289 - lr: 3.0518e-07


Calculating activations statistics...
For each - except for last - layer the calculation is done twice: with and without the activation function
Training Completed...                                               
 
Total time of training the network: 1269.2654052080002
