cem-tf:
  seed: null                          # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  cem_outer_it: 3                    #how many outer iterations to use
  cem_initial_action_stdev: 0.5
  num_rollouts: 200          #how many rollouts per outer cem iteration
  predictor_specification: "ODE_TF"    # Can be "ODE", "ODE_TF", network/GP name (possibly with path) e.g. 'GRU-6IN-32H1-32H2-5OUT-0' or a name of a custom predictor. For more info see config_predictors in SI_Toolkit_ASF
  cost_function_specification: default  # One of "default", "quadratic_boundary_grad", "quadratic_boundary_nonconvex", "quadratic_boundary"
  cem_stdev_min: 0.01
  cem_best_k: 40
  warmup: false
  warmup_iterations: 250
  controller_logging: True
cem-gmm-tf:
  seed: null                          # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  cem_outer_it: 3                    #how many outer iterations to use
  num_rollouts: 200          #how many rollouts per outer cem iteration
  predictor_specification: "ODE_TF"    # Can be "ODE", "ODE_TF", network/GP name (possibly with path) e.g. 'GRU-6IN-32H1-32H2-5OUT-0' or a name of a custom predictor. For more info see config_predictors in SI_Toolkit_ASF
  cost_function_specification: default  # One of "default", "quadratic_boundary_grad", "quadratic_boundary_nonconvex", "quadratic_boundary"
  cem_stdev_min: 0.01
  cem_initial_action_stdev: 0.5
  cem_best_k: 40
  controller_logging: True
cem-naive-grad-tf:
  seed: null                          # If null, random seed based on datetime is used
  mpc_horizon: 35                       # steps
  cem_outer_it: 1                       # how many outer iterations to use
  num_rollouts: 200                     # how many rollouts per outer cem iteration
  predictor_specification: "ODE_TF"    # Can be "ODE", "ODE_TF", network/GP name (possibly with path) e.g. 'GRU-6IN-32H1-32H2-5OUT-0' or a name of a custom predictor. For more info see config_predictors in SI_Toolkit_ASF
  cost_function_specification: default  # One of "default", "quadratic_boundary_grad", "quadratic_boundary_nonconvex", "quadratic_boundary"
  cem_stdev_min: 0.1
  cem_initial_action_stdev: 0.5
  cem_best_k: 40
  learning_rate: 0.1
  gradmax_clip: 10
  controller_logging: True
cem-grad-bharadhwaj-tf:
  seed: null                          # If null, random seed based on datetime is used
  controller_logging: true
  mpc_horizon: 50                       # steps
  predictor_specification: "ODE_TF"    # Can be "ODE", "ODE_TF", network/GP name (possibly with path) e.g. 'GRU-6IN-32H1-32H2-5OUT-0' or a name of a custom predictor. For more info see config_predictors in SI_Toolkit_ASF
  cost_function_specification: default  # One of "default", "quadratic_boundary_grad", "quadratic_boundary_nonconvex", "quadratic_boundary"
  learning_rate: 0.05
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1.0e-08
  num_rollouts: 32
  cem_best_k: 8
  cem_outer_it: 2
  cem_initial_action_stdev: 2
  cem_stdev_min: 1.e-6
  gradmax_clip: 5
  warmup: false
  warmup_iterations: 250
gradient-tf:
  seed: null                            # If null, random seed based on datetime is used
  mpc_horizon: 35                       # steps
  predictor_specification: "ODE_TF"    # Can be "ODE", "ODE_TF", network/GP name (possibly with path) e.g. 'GRU-6IN-32H1-32H2-5OUT-0' or a name of a custom predictor. For more info see config_predictors in SI_Toolkit_ASF
  cost_function_specification: default  # One of "default", "quadratic_boundary_grad", "quadratic_boundary_nonconvex", "quadratic_boundary"
  learning_rate: 0.05
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1.0e-07
  rtol: 1.0e-3
  gradient_steps: 5
  num_rollouts: 40
  initial_action_stdev: 0.5
  gradmax_clip: 5
  warmup: false
  warmup_iterations: 250
  controller_logging: True
mppi-optimize-tf:
  seed: null                            # If null, random seed based on datetime is used
  dt: 0.02                              # sec
  mppi_LR: 0.02
  adam_beta_1: 0.4                      #default: 0.9
  adam_beta_2: 0.8                      #default: 0.999
  adam_epsilon: 1.0e-7                  #default: 1.0e-7
  gradmax_clip: 1000
  mpc_horizon: 35                       # steps
  num_rollouts: 400                     # Number of Monte Carlo samples
  predictor_specification: "ODE_TF"    # Can be "ODE", "ODE_TF", network/GP name (possibly with path) e.g. 'GRU-6IN-32H1-32H2-5OUT-0' or a name of a custom predictor. For more info see config_predictors in SI_Toolkit_ASF
  cost_function_specification: default  # One of "default", "quadratic_boundary_grad", "quadratic_boundary_nonconvex", "quadratic_boundary"
  cc_weight: 1.0
  R: 1.0                                # How much to punish Q
  LBD: 100.0                            # Cost parameter lambda
  NU: 1000.0                            # Exploration variance
  SQRTRHOINV: 0.02
  GAMMA: 1.00                           # Future cost discount
  SAMPLING_TYPE: "interpolated"         # One of ["iid", "random_walk", "uniform", "repeated", "interpolated"]
  optim_steps: 10
  controller_logging: True
dist-adam-resamp2-tf:
  seed: null                            # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  SAMPLING_TYPE: interpolated
  interpolation_step: 10
  learning_rate: 0.05
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1.0e-08
  gradmax_clip: 5
  rtol: 1.0e-3
  num_rollouts: 32
  predictor_specification: "ODE_TF"    # Can be "ODE", "ODE_TF", network/GP name (possibly with path) e.g. 'GRU-6IN-32H1-32H2-5OUT-0' or a name of a custom predictor. For more info see config_predictors in SI_Toolkit_ASF
  cost_function_specification: default  # One of "default", "quadratic_boundary_grad", "quadratic_boundary_nonconvex", "quadratic_boundary"
  opt_keep_k: 8
  outer_its: 2
  resamp_per: 10
  sample_stdev: 0.5
  warmup: false
  warmup_iterations: 250
  controller_logging: True
rpgd-tf:
  seed: null                            # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  SAMPLING_TYPE: interpolated
  interpolation_step: 10
  learning_rate: 0.05
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1.0e-08
  gradmax_clip: 5
  rtol: 1.0e-3
  num_rollouts: 32
  predictor_specification: "ODE_TF"    # Can be "ODE", "ODE_TF", network/GP name (possibly with path) e.g. 'GRU-6IN-32H1-32H2-5OUT-0' or a name of a custom predictor. For more info see config_predictors in SI_Toolkit_ASF
  cost_function_specification: default  # One of "default", "quadratic_boundary_grad", "quadratic_boundary_nonconvex", "quadratic_boundary"
  opt_keep_k: 8
  outer_its: 2
  resamp_per: 10
  sample_stdev: 0.5
  warmup: false
  warmup_iterations: 250
  controller_logging: True
rpgd-me-tf:
  seed: null                            # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  SAMPLING_TYPE: null
  SAMPLING_DISTRIBUTION: uniform  # "normal" or "uniform"
  interpolation_step: 10
  learning_rate: 0.01
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1.0e-08
  maximum_entropy_alpha: 0.0
  gradmax_clip: 10
  rtol: 1.0e-3
  num_rollouts: 32
  predictor_specification: "ODE_TF"    # Can be "ODE", "ODE_TF", network/GP name (possibly with path) e.g. 'GRU-6IN-32H1-32H2-5OUT-0' or a name of a custom predictor. For more info see config_predictors in SI_Toolkit_ASF
  cost_function_specification: default  # One of "default", "quadratic_boundary_grad", "quadratic_boundary_nonconvex", "quadratic_boundary"
  opt_keep_k: 0
  outer_its: 25
  resamp_per: 1
  sample_stdev: 0.5
  warmup: false
  warmup_iterations: 250
  controller_logging: True
rpgd_ml_tf:
  seed: null                            # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  SAMPLING_DISTRIBUTION: uniform  # "normal" or "uniform"
  SAMPLING_TYPE: null
  interpolation_step: 10
  learning_rate: 0.01
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1.0e-08
  maximum_entropy_alpha: 0.1
  gradmax_clip: 10
  rtol: 1.0e-3
  num_rollouts: 32
  predictor_specification: "ODE_TF"    # Can be "ODE", "ODE_TF", network/GP name (possibly with path) e.g. 'GRU-6IN-32H1-32H2-5OUT-0' or a name of a custom predictor. For more info see config_predictors in SI_Toolkit_ASF
  cost_function_specification: default  # One of "default", "quadratic_boundary_grad", "quadratic_boundary_nonconvex", "quadratic_boundary"
  opt_keep_k: 8
  outer_its: 5
  resamp_per: 1
  sample_stdev: 0.5
  warmup: false
  warmup_iterations: 250
  controller_logging: True
rpgd-particle-tf:
  seed: null                            # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  SAMPLING_DISTRIBUTION: uniform  # "normal" or "uniform"
  SAMPLING_TYPE: null
  interpolation_step: 10
  learning_rate: 0.01
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1.0e-08
  maximum_entropy_alpha: 0.1
  gradmax_clip: 10
  rtol: 1.0e-3
  num_rollouts: 32
  predictor_specification: "ODE_TF"    # Can be "ODE", "ODE_TF", network/GP name (possibly with path) e.g. 'GRU-6IN-32H1-32H2-5OUT-0' or a name of a custom predictor. For more info see config_predictors in SI_Toolkit_ASF
  cost_function_specification: default  # One of "default", "quadratic_boundary_grad", "quadratic_boundary_nonconvex", "quadratic_boundary"
  opt_keep_k: 8
  outer_its: 5
  resamp_per: 1
  sample_stdev: 0.5
  warmup: false
  warmup_iterations: 250
  controller_logging: True
mppi-var-tf:
  seed: null                          # If null, random seed based on datetime is used
  dt: 0.02                              # sec
  mpc_horizon: 35                       # steps
  num_rollouts: 400                     # Number of Monte Carlo samples
  SAMPLING_TYPE: "interpolated" #if interpolated: linear interpolation; else iid
  interpolation_step: 10                #interpolation stepsize when sampling
  cc_weight: 1.0
  predictor_specification: "ODE_TF"    # Can be "ODE", "ODE_TF", network/GP name (possibly with path) e.g. 'GRU-6IN-32H1-32H2-5OUT-0' or a name of a custom predictor. For more info see config_predictors in SI_Toolkit_ASF
  cost_function_specification: default  # One of "default", "quadratic_boundary_grad", "quadratic_boundary_nonconvex", "quadratic_boundary"
  R: 1.0                                # How much to punish Q
  # mc stands for mathematical correct, as this controller uses the formula from the paper
  LBD_mc: 10.0                          # Cost parameter lambda
  SQRTRHOINV_mc: 0.002                  # Sampling variance
  NU_mc: 20.0                           # Exploration variance
  GAMMA: 1.00                           # Future cost discount
  LR: 1000                              # Learning rate for adaption of variance, !!! Set to 0 to retrieve a mppi version in accordance with mppi paper
  STDEV_min: 0.01                       # Maximal variance for sampling
  STDEV_max: 10                         # Minimal sampling variance for sampling
  max_grad_norm: 100000                 # max norm of gradient such that ||gradient||_2
  controller_logging: True
mppi:
  seed: null                            # Seed for rng, for MPPI only, put null to set random seed (do it when you generate data for training!)
  dt: 0.02                              # sec
  mpc_horizon: 35                       # steps
  num_rollouts: 3500                    # Number of Monte Carlo samples
  update_every: 1                       # Cost weighted update of inputs every ... steps
  predictor_specification: "ODE_TF"    # Can be "ODE", "ODE_TF", network/GP name (possibly with path) e.g. 'GRU-6IN-32H1-32H2-5OUT-0'/'SGP_30' or a name of a custom predictor. For more info see config_predictors in SI_Toolkit_ASF
  cost_function_specification: default  # One of "default", "quadratic_boundary_grad", "quadratic_boundary_nonconvex", "quadratic_boundary"
  dd_weight: 120.0
  ep_weight: 50000.0
  ekp_weight: 0.01
  ekc_weight: 5.0
  cc_weight: 1.0
  ccrc_weight: 1.0
  cost_noise: 0.0                       # Noise on stage cost weights by +/- this value, we usually set 0.5 to explore various controllers while collecting data for training, 0 othewise
  control_noise:                        # Defined in cartpole config
  R: 1.0                                # How much to punish Q
  LBD: 100.0                            # Cost parameter lambda
  NU: 1000.0                            # Exploration variance
  SQRTRHOINV: 0.02                      # Sampling variance
  GAMMA: 1.00                           # Future cost discount
  SAMPLING_TYPE: "interpolated"         # One of ["iid", "random_walk", "uniform", "repeated", "interpolated"]
  controller_logging: False                        # Collect and show detailed insights into the controller's behavior
  WASH_OUT_LEN: 100                     # Only matters if RNN used as predictor; For how long MPPI should be desactivated (replaced either with LQR or random input) to give memory units time to settle
mppi-tf:
  seed: null                          # Seed for rng, for MPPI only, put null to set random seed (do it when you generate data for training!)
  dt: 0.02                              # sec
  mpc_horizon: 35                       # steps
  num_rollouts: 3500                    # Number of Monte Carlo samples
  update_every: 1                       # Cost weighted update of inputs every ... steps
  predictor_specification: "ODE_TF"    # Can be "ODE", "ODE_TF", network/GP name (possibly with path) e.g. 'GRU-6IN-32H1-32H2-5OUT-0', 'SGP_30' or a name of a custom predictor. For more info see config_predictors in SI_Toolkit_ASF
  cost_function_specification: default  # One of "default", "quadratic_boundary_grad", "quadratic_boundary_nonconvex", "quadratic_boundary"
  cc_weight: 1.0
  cost_noise: 0.0                       # Noise on stage cost weights by +/- this value, we usually set 0.5 to explore various controllers while collecting data for training, 0 othewise
  control_noise:                        # Defined in cartpole config
  R: 1.0                                # How much to punish Q
  LBD: 100.0                            # Cost parameter lambda
  NU: 1000.0                            # Exploration variance
  SQRTRHOINV: 0.03                      # Sampling variance
  GAMMA: 1.00                           # Future cost discount
  SAMPLING_TYPE: "interpolated"         # One of ["iid", "random_walk", "uniform", "repeated", "interpolated"]
  controller_logging: False                        # Collect and show detailed insights into the controller's behavior
  WASH_OUT_LEN: 100                     # Only matters if RNN used as predictor; For how long MPPI should be desactivated (replaced either with LQR or random input) to give memory units time to settle
  CLIP_CONTROL_INPUT: [1.0]             # How to clip control input, symmetric
random-action-tf:
  seed: null                          # Seed for rng, for MPPI only, put null to set random seed (do it when you generate data for training!)
  mpc_horizon: 35                      # steps
  num_rollouts: 320
  predictor_specification: "ODE_TF"    # Can be "ODE", "ODE_TF", network/GP name (possibly with path) e.g. 'GRU-6IN-32H1-32H2-5OUT-0', 'SGP_30' or a name of a custom predictor. For more info see config_predictors in SI_Toolkit_ASF
  cost_function_specification: default  # One of "default", "quadratic_boundary_grad", "quadratic_boundary_nonconvex", "quadratic_boundary"
  controller_logging: False                        # Collect and show detailed insights into the controller's behavior
custom-mpc-scipy:
  seed: null                          # If null, random seed based on datetime is used
  # method: 'L-BFGS-B'
  method: 'SLSQP'
  ftol: 1.0e-8
  mpc_horizon: 10                       # steps
  # weights
  wr: 0.001  # rterm
  l1: 100.0  # angle_cost
  l1_2: 0.0  # angle_sin_cost
  l2: 0.0  # angleD_cost
  l3: 0.0  # position_cost
  l4: 0.01  # positionD_cost
  m1: 0.0  # angle_sin_cost
  m2: 0.0  # angleD_cost
  m3: 0.0  # position_cost
  m4: 0.0  # positionD_cost
  controller_logging: True
do-mpc-discrete:
  dt: 0.02  # s
  mpc_horizon: 50                       # steps
  num_rollouts: 1
  controller_logging: True
do-mpc:
  seed: null                          # If null, random seed based on datetime is used
  dt: 0.02                              # sec
  mpc_horizon: 50                       # steps
  num_rollouts: 1
  # Perturbation factors:
  # Change of output from optimal
  p_Q: 0.00
  # Random change of cost function by factor
  p_position: 0.0
  p_positionD: 0.0
  p_angle: 0.0
  # Cost factor
  l_angle: 0.1
  l_position: 1.0
  l_positionD: 0.1
  controller_logging: True
lqr:
  seed: null  # Seed for rng, for lqr only, put null to set random seed (do it when you generate data for training!)
  Q: [10.0, 1.0, 1.0, 1.0]
  R: 10.0
  control_noise:  # Defined in cartpole config
  controller_logging: True
pid:
  P_angle: 9.0
  I_angle: 0.0
  D_angle: 0.0
  P_position: 0.1
  I_position: 0.0
  D_position: 0.1
  controller_logging: True
mpc-opti:
  mpc_horizon: 10                       # steps
  controller_logging: True
neural-imitator-tf:
  seed: null                            # If null, random seed based on datetime is used
  PATH_TO_MODELS: './Control_Toolkit_ASF/Controllers/models_for_neural_imitator_tf/'
  net_name: 'GRU-6IN-32H1-32H2-1OUT-4'
  mpc_horizon: 40
  num_rollouts: 1
  controller_logging: True
neural-imitator-pytorch:
  seed: null                            # If null, random seed based on datetime is used
  PATH_TO_MODELS: './Control_Toolkit_ASF/Controllers/models_for_neural_imitator_tf/'
  net_name: 'GRU-6IN-32H1-32H2-1OUT-4'
  mpc_horizon: 40
  num_rollouts: 1
  controller_logging: True
secloc:
  log_base: 1.05
  dt: 1 # In the Arduino code is 1000
  ref_period: 1
  dead_band: 0.0025  # Radians
  pid_Kp: 15.0
  pid_Kd: 0.0
  pid_Ki: 1.0
  #secloc_motor_map: 128